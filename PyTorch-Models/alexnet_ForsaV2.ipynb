{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f9ac6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utilis_ForsaV2 import *\n",
    "import utilis_ForsaV2\n",
    "# !pip install fxpmath\\\n",
    "from fxpmath import Fxp\n",
    "import time\n",
    "word_size  = 8\n",
    "frac_size = 6\n",
    "utilis_ForsaV2.word_size = word_size\n",
    "utilis_ForsaV2.frac_size = frac_size\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from transforms import *\n",
    "# from models_cust import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c754bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\huruy/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'alexnet', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a90752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to visualize it in netron locally\n",
    "# # Assuming `model` is your PyTorch model\n",
    "# model_path = './PretrainedModels/alexnetPretrainedIM1K.pth'\n",
    "\n",
    "# # # Save the entire model, including its architecture and trained parameters\n",
    "# # # torch.save(model, model_path)\n",
    "# torch.jit.script(model).save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7bd9f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8018fb7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
      "              ReLU-2           [-1, 64, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 61,100,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 8.38\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 242.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model.to('cuda'), (3, 224, 224)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422a3f8",
   "metadata": {},
   "source": [
    "# Demonstrating sorting for AlexNet\n",
    "a) Regular convolution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ddf79d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 88294.0\n",
      "Switching after sorting 79591.0\n",
      "Percentage of switching reduction 9.856841914512877 %\n",
      "Switching before sorting 1060179.0\n",
      "Switching after sorting 965277.0\n",
      "Percentage of switching reduction 8.951507245474584 %\n",
      "Switching before sorting 2347256.0\n",
      "Switching after sorting 2138910.0\n",
      "Percentage of switching reduction 8.876151557392973 %\n",
      "Switching before sorting 3048703.0\n",
      "Switching after sorting 2835337.0\n",
      "Percentage of switching reduction 6.998582675977293 %\n",
      "Switching before sorting 2022532.0\n",
      "Switching after sorting 1834344.0\n",
      "Percentage of switching reduction 9.30457466185949 %\n"
     ]
    }
   ],
   "source": [
    "No_layers=5 # to exlude classifier network\n",
    "sw_wt = np.zeros(No_layers)\n",
    "sw_bias = np.zeros(No_layers)\n",
    "sw_wt_sorted = np.zeros(No_layers)\n",
    "sw_bias_sorted = np.zeros(No_layers)\n",
    "########## sorting features.0 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.features[0].weight)\n",
    "model.features[0].weight.data, _, sw_wt[0], sw_wt_sorted[0]  = compare_sw_sort(model.features[0].weight.data, new_indx1, -3, printsumm=True)\n",
    "model.features[0].bias.data, _, sw_bias[0], sw_bias_sorted[0]  = compare_sw_sort(model.features[0].bias.data, new_indx1, -1)\n",
    "# plot_dist(model.features[0][0].weight)\n",
    "########## rearranging features.3 ##########\n",
    "model.features[3].weight.data = model.features[3].weight[:, new_indx1, :, :]\n",
    "\n",
    "# ########## sorting features.3 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.features[3].weight)\n",
    "model.features[3].weight.data, _, sw_wt[1], sw_wt_sorted[1]  = compare_sw_sort(model.features[3].weight.data, new_indx1, -3, printsumm=True)\n",
    "model.features[3].bias.data, _, sw_bias[1], sw_bias_sorted[1]  = compare_sw_sort(model.features[3].bias.data, new_indx1, -1)\n",
    "# plot_dist(model.features[0][0].weight)\n",
    "########## rearranging features.3 ##########\n",
    "model.features[6].weight.data = model.features[6].weight[:, new_indx1, :, :]\n",
    "\n",
    "# ########## sorting features.6 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.features[6].weight)\n",
    "model.features[6].weight.data, _, sw_wt[2], sw_wt_sorted[2]  = compare_sw_sort(model.features[6].weight.data, new_indx1, -3, printsumm=True)\n",
    "model.features[6].bias.data, _, sw_bias[2], sw_bias_sorted[2]  = compare_sw_sort(model.features[6].bias.data, new_indx1, -1)\n",
    "# plot_dist(model.features[0][0].weight)\n",
    "########## rearranging features.3 ##########\n",
    "model.features[8].weight.data = model.features[8].weight[:, new_indx1, :, :]\n",
    "\n",
    "# ########## sorting features.8 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.features[8].weight)\n",
    "model.features[8].weight.data, _, sw_wt[3], sw_wt_sorted[3]  = compare_sw_sort(model.features[8].weight.data, new_indx1, -3, printsumm=True)\n",
    "model.features[8].bias.data, _, sw_bias[3], sw_bias_sorted[3]  = compare_sw_sort(model.features[8].bias.data, new_indx1, -1)\n",
    "# plot_dist(model.features[0][0].weight)\n",
    "########## rearranging features.3 ##########\n",
    "model.features[10].weight.data = model.features[10].weight[:, new_indx1, :, :]\n",
    "\n",
    "# ########## sorting features.11 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.features[10].weight)\n",
    "model.features[10].weight.data, _, sw_wt[4], sw_wt_sorted[4]  = compare_sw_sort(model.features[10].weight.data, new_indx1, -3, printsumm=True)\n",
    "model.features[10].bias.data, _, sw_bias[4], sw_bias_sorted[4]  = compare_sw_sort(model.features[10].bias.data, new_indx1, -1)\n",
    "# plot_dist(model.features[0][0].weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "212b5555",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## rearranging classifier.1 ##########\n",
    "# Reshaping first classifier weight to rearrange prior to its sort\n",
    "fc1_weight = model.classifier[1].weight\n",
    "fc1_weight = fc1_weight.view(4096, 256, 6, 6)\n",
    "new_fc1_weight = fc1_weight[:, new_indx1, :, :]\n",
    "model.classifier[1].weight.data = new_fc1_weight.view(new_fc1_weight.shape[0], -1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ddf4b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 32204568.0\n",
      "Switching after sorting 29309605.0\n",
      "Percentage of switching reduction 8.989293071715789 %\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 5 is out of bounds for axis 0 with size 5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ########## sorting classifier.1 ##########\u001b[39;00m\n\u001b[0;32m      2\u001b[0m _, new_indx1 \u001b[38;5;241m=\u001b[39m sortFullMatrix_V2(model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mweight)\n\u001b[1;32m----> 3\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata, _, sw_wt[\u001b[38;5;241m5\u001b[39m], sw_wt_sorted[\u001b[38;5;241m5\u001b[39m]  \u001b[38;5;241m=\u001b[39m compare_sw_sort(model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata, new_indx1, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, isconv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, printsumm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata, _, sw_bias[\u001b[38;5;241m5\u001b[39m], sw_bias_sorted[\u001b[38;5;241m5\u001b[39m]  \u001b[38;5;241m=\u001b[39m compare_sw_sort(model\u001b[38;5;241m.\u001b[39mclassifier[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata, new_indx1, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, isconv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m########## rearranging classifier.4 ##########\u001b[39;00m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 5 is out of bounds for axis 0 with size 5"
     ]
    }
   ],
   "source": [
    "# ########## sorting classifier.1 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.classifier[1].weight)\n",
    "model.classifier[1].weight.data, _, sw_wt[5], sw_wt_sorted[5]  = compare_sw_sort(model.classifier[1].weight.data, new_indx1, -1, isconv=False, printsumm=True)\n",
    "model.classifier[1].bias.data, _, sw_bias[5], sw_bias_sorted[5]  = compare_sw_sort(model.classifier[1].bias.data, new_indx1, -1, isconv=False)\n",
    "########## rearranging classifier.4 ##########\n",
    "model.classifier[4].weight.data = model.classifier[4].weight[:, new_indx1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12ff9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########## sorting classifier.4 ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.classifier[4].weight)\n",
    "model.classifier[4].weight.data, _, sw_wt[6], sw_wt_sorted[6]  = compare_sw_sort(model.classifier[4].weight.data, new_indx1, -1, isconv=False, printsumm=True)\n",
    "model.classifier[4].bias.data, _, sw_bias[6], sw_bias_sorted[6]  = compare_sw_sort(model.classifier[4].bias.data, new_indx1, -1, isconv=False)\n",
    "########## rearranging classifier.6 ##########\n",
    "model.classifier[6].weight.data = model.classifier[6].weight[:, new_indx1]\n",
    "###### No need to re order the last fc to keep the order of output as original model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a937c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('switching activity of weight before sorting: ', sw_wt)\n",
    "print('switching activity of weight before sorting: ', sw_wt_sorted)\n",
    "print('Percentage of switching activity of weight changes: ', (sw_wt - sw_wt_sorted)*100/sw_wt)\n",
    "print('switching activity of bias after sorting: ', sw_bias)\n",
    "print('switching activity of bias after sorting: ', sw_bias_sorted)\n",
    "print('Percentage of switching activity of biases changes: ', (sw_bias - sw_bias_sorted)*100/sw_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b6f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "filename = 'dog.jpg'\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e8f3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8ea99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e73d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9847ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
