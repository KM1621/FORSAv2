{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ebc8aa3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88f9ac6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from utilis_ForsaV2 import *\n",
    "import utilis_ForsaV2\n",
    "# !pip install fxpmath\\\n",
    "from fxpmath import Fxp\n",
    "import time\n",
    "word_size  = 8\n",
    "frac_size = 6\n",
    "utilis_ForsaV2.word_size = word_size\n",
    "utilis_ForsaV2.frac_size = frac_size\n",
    "\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from transforms import *\n",
    "# from models_cust import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "18601f39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\huruy/.cache\\torch\\hub\\pytorch_vision_v0.10.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GoogLeNet(\n",
       "  (conv1): BasicConv2d(\n",
       "    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (conv2): BasicConv2d(\n",
       "    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (conv3): BasicConv2d(\n",
       "    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception3a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception3b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception4a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4c): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4d): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception4e): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)\n",
       "  (inception5a): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (inception5b): Inception(\n",
       "    (branch1): BasicConv2d(\n",
       "      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch2): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch3): Sequential(\n",
       "      (0): BasicConv2d(\n",
       "        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (branch4): Sequential(\n",
       "      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)\n",
       "      (1): BasicConv2d(\n",
       "        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (aux1): None\n",
       "  (aux2): None\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=1024, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'googlenet', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2bcc7e42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "       BasicConv2d-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "       BasicConv2d-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8          [-1, 192, 56, 56]         110,592\n",
      "       BatchNorm2d-9          [-1, 192, 56, 56]             384\n",
      "      BasicConv2d-10          [-1, 192, 56, 56]               0\n",
      "        MaxPool2d-11          [-1, 192, 28, 28]               0\n",
      "           Conv2d-12           [-1, 64, 28, 28]          12,288\n",
      "      BatchNorm2d-13           [-1, 64, 28, 28]             128\n",
      "      BasicConv2d-14           [-1, 64, 28, 28]               0\n",
      "           Conv2d-15           [-1, 96, 28, 28]          18,432\n",
      "      BatchNorm2d-16           [-1, 96, 28, 28]             192\n",
      "      BasicConv2d-17           [-1, 96, 28, 28]               0\n",
      "           Conv2d-18          [-1, 128, 28, 28]         110,592\n",
      "      BatchNorm2d-19          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-20          [-1, 128, 28, 28]               0\n",
      "           Conv2d-21           [-1, 16, 28, 28]           3,072\n",
      "      BatchNorm2d-22           [-1, 16, 28, 28]              32\n",
      "      BasicConv2d-23           [-1, 16, 28, 28]               0\n",
      "           Conv2d-24           [-1, 32, 28, 28]           4,608\n",
      "      BatchNorm2d-25           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-26           [-1, 32, 28, 28]               0\n",
      "        MaxPool2d-27          [-1, 192, 28, 28]               0\n",
      "           Conv2d-28           [-1, 32, 28, 28]           6,144\n",
      "      BatchNorm2d-29           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-30           [-1, 32, 28, 28]               0\n",
      "        Inception-31          [-1, 256, 28, 28]               0\n",
      "           Conv2d-32          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-33          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-34          [-1, 128, 28, 28]               0\n",
      "           Conv2d-35          [-1, 128, 28, 28]          32,768\n",
      "      BatchNorm2d-36          [-1, 128, 28, 28]             256\n",
      "      BasicConv2d-37          [-1, 128, 28, 28]               0\n",
      "           Conv2d-38          [-1, 192, 28, 28]         221,184\n",
      "      BatchNorm2d-39          [-1, 192, 28, 28]             384\n",
      "      BasicConv2d-40          [-1, 192, 28, 28]               0\n",
      "           Conv2d-41           [-1, 32, 28, 28]           8,192\n",
      "      BatchNorm2d-42           [-1, 32, 28, 28]              64\n",
      "      BasicConv2d-43           [-1, 32, 28, 28]               0\n",
      "           Conv2d-44           [-1, 96, 28, 28]          27,648\n",
      "      BatchNorm2d-45           [-1, 96, 28, 28]             192\n",
      "      BasicConv2d-46           [-1, 96, 28, 28]               0\n",
      "        MaxPool2d-47          [-1, 256, 28, 28]               0\n",
      "           Conv2d-48           [-1, 64, 28, 28]          16,384\n",
      "      BatchNorm2d-49           [-1, 64, 28, 28]             128\n",
      "      BasicConv2d-50           [-1, 64, 28, 28]               0\n",
      "        Inception-51          [-1, 480, 28, 28]               0\n",
      "        MaxPool2d-52          [-1, 480, 14, 14]               0\n",
      "           Conv2d-53          [-1, 192, 14, 14]          92,160\n",
      "      BatchNorm2d-54          [-1, 192, 14, 14]             384\n",
      "      BasicConv2d-55          [-1, 192, 14, 14]               0\n",
      "           Conv2d-56           [-1, 96, 14, 14]          46,080\n",
      "      BatchNorm2d-57           [-1, 96, 14, 14]             192\n",
      "      BasicConv2d-58           [-1, 96, 14, 14]               0\n",
      "           Conv2d-59          [-1, 208, 14, 14]         179,712\n",
      "      BatchNorm2d-60          [-1, 208, 14, 14]             416\n",
      "      BasicConv2d-61          [-1, 208, 14, 14]               0\n",
      "           Conv2d-62           [-1, 16, 14, 14]           7,680\n",
      "      BatchNorm2d-63           [-1, 16, 14, 14]              32\n",
      "      BasicConv2d-64           [-1, 16, 14, 14]               0\n",
      "           Conv2d-65           [-1, 48, 14, 14]           6,912\n",
      "      BatchNorm2d-66           [-1, 48, 14, 14]              96\n",
      "      BasicConv2d-67           [-1, 48, 14, 14]               0\n",
      "        MaxPool2d-68          [-1, 480, 14, 14]               0\n",
      "           Conv2d-69           [-1, 64, 14, 14]          30,720\n",
      "      BatchNorm2d-70           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-71           [-1, 64, 14, 14]               0\n",
      "        Inception-72          [-1, 512, 14, 14]               0\n",
      "           Conv2d-73          [-1, 160, 14, 14]          81,920\n",
      "      BatchNorm2d-74          [-1, 160, 14, 14]             320\n",
      "      BasicConv2d-75          [-1, 160, 14, 14]               0\n",
      "           Conv2d-76          [-1, 112, 14, 14]          57,344\n",
      "      BatchNorm2d-77          [-1, 112, 14, 14]             224\n",
      "      BasicConv2d-78          [-1, 112, 14, 14]               0\n",
      "           Conv2d-79          [-1, 224, 14, 14]         225,792\n",
      "      BatchNorm2d-80          [-1, 224, 14, 14]             448\n",
      "      BasicConv2d-81          [-1, 224, 14, 14]               0\n",
      "           Conv2d-82           [-1, 24, 14, 14]          12,288\n",
      "      BatchNorm2d-83           [-1, 24, 14, 14]              48\n",
      "      BasicConv2d-84           [-1, 24, 14, 14]               0\n",
      "           Conv2d-85           [-1, 64, 14, 14]          13,824\n",
      "      BatchNorm2d-86           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-87           [-1, 64, 14, 14]               0\n",
      "        MaxPool2d-88          [-1, 512, 14, 14]               0\n",
      "           Conv2d-89           [-1, 64, 14, 14]          32,768\n",
      "      BatchNorm2d-90           [-1, 64, 14, 14]             128\n",
      "      BasicConv2d-91           [-1, 64, 14, 14]               0\n",
      "        Inception-92          [-1, 512, 14, 14]               0\n",
      "           Conv2d-93          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-94          [-1, 128, 14, 14]             256\n",
      "      BasicConv2d-95          [-1, 128, 14, 14]               0\n",
      "           Conv2d-96          [-1, 128, 14, 14]          65,536\n",
      "      BatchNorm2d-97          [-1, 128, 14, 14]             256\n",
      "      BasicConv2d-98          [-1, 128, 14, 14]               0\n",
      "           Conv2d-99          [-1, 256, 14, 14]         294,912\n",
      "     BatchNorm2d-100          [-1, 256, 14, 14]             512\n",
      "     BasicConv2d-101          [-1, 256, 14, 14]               0\n",
      "          Conv2d-102           [-1, 24, 14, 14]          12,288\n",
      "     BatchNorm2d-103           [-1, 24, 14, 14]              48\n",
      "     BasicConv2d-104           [-1, 24, 14, 14]               0\n",
      "          Conv2d-105           [-1, 64, 14, 14]          13,824\n",
      "     BatchNorm2d-106           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-107           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-108          [-1, 512, 14, 14]               0\n",
      "          Conv2d-109           [-1, 64, 14, 14]          32,768\n",
      "     BatchNorm2d-110           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-111           [-1, 64, 14, 14]               0\n",
      "       Inception-112          [-1, 512, 14, 14]               0\n",
      "          Conv2d-113          [-1, 112, 14, 14]          57,344\n",
      "     BatchNorm2d-114          [-1, 112, 14, 14]             224\n",
      "     BasicConv2d-115          [-1, 112, 14, 14]               0\n",
      "          Conv2d-116          [-1, 144, 14, 14]          73,728\n",
      "     BatchNorm2d-117          [-1, 144, 14, 14]             288\n",
      "     BasicConv2d-118          [-1, 144, 14, 14]               0\n",
      "          Conv2d-119          [-1, 288, 14, 14]         373,248\n",
      "     BatchNorm2d-120          [-1, 288, 14, 14]             576\n",
      "     BasicConv2d-121          [-1, 288, 14, 14]               0\n",
      "          Conv2d-122           [-1, 32, 14, 14]          16,384\n",
      "     BatchNorm2d-123           [-1, 32, 14, 14]              64\n",
      "     BasicConv2d-124           [-1, 32, 14, 14]               0\n",
      "          Conv2d-125           [-1, 64, 14, 14]          18,432\n",
      "     BatchNorm2d-126           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-127           [-1, 64, 14, 14]               0\n",
      "       MaxPool2d-128          [-1, 512, 14, 14]               0\n",
      "          Conv2d-129           [-1, 64, 14, 14]          32,768\n",
      "     BatchNorm2d-130           [-1, 64, 14, 14]             128\n",
      "     BasicConv2d-131           [-1, 64, 14, 14]               0\n",
      "       Inception-132          [-1, 528, 14, 14]               0\n",
      "          Conv2d-133          [-1, 256, 14, 14]         135,168\n",
      "     BatchNorm2d-134          [-1, 256, 14, 14]             512\n",
      "     BasicConv2d-135          [-1, 256, 14, 14]               0\n",
      "          Conv2d-136          [-1, 160, 14, 14]          84,480\n",
      "     BatchNorm2d-137          [-1, 160, 14, 14]             320\n",
      "     BasicConv2d-138          [-1, 160, 14, 14]               0\n",
      "          Conv2d-139          [-1, 320, 14, 14]         460,800\n",
      "     BatchNorm2d-140          [-1, 320, 14, 14]             640\n",
      "     BasicConv2d-141          [-1, 320, 14, 14]               0\n",
      "          Conv2d-142           [-1, 32, 14, 14]          16,896\n",
      "     BatchNorm2d-143           [-1, 32, 14, 14]              64\n",
      "     BasicConv2d-144           [-1, 32, 14, 14]               0\n",
      "          Conv2d-145          [-1, 128, 14, 14]          36,864\n",
      "     BatchNorm2d-146          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-147          [-1, 128, 14, 14]               0\n",
      "       MaxPool2d-148          [-1, 528, 14, 14]               0\n",
      "          Conv2d-149          [-1, 128, 14, 14]          67,584\n",
      "     BatchNorm2d-150          [-1, 128, 14, 14]             256\n",
      "     BasicConv2d-151          [-1, 128, 14, 14]               0\n",
      "       Inception-152          [-1, 832, 14, 14]               0\n",
      "       MaxPool2d-153            [-1, 832, 7, 7]               0\n",
      "          Conv2d-154            [-1, 256, 7, 7]         212,992\n",
      "     BatchNorm2d-155            [-1, 256, 7, 7]             512\n",
      "     BasicConv2d-156            [-1, 256, 7, 7]               0\n",
      "          Conv2d-157            [-1, 160, 7, 7]         133,120\n",
      "     BatchNorm2d-158            [-1, 160, 7, 7]             320\n",
      "     BasicConv2d-159            [-1, 160, 7, 7]               0\n",
      "          Conv2d-160            [-1, 320, 7, 7]         460,800\n",
      "     BatchNorm2d-161            [-1, 320, 7, 7]             640\n",
      "     BasicConv2d-162            [-1, 320, 7, 7]               0\n",
      "          Conv2d-163             [-1, 32, 7, 7]          26,624\n",
      "     BatchNorm2d-164             [-1, 32, 7, 7]              64\n",
      "     BasicConv2d-165             [-1, 32, 7, 7]               0\n",
      "          Conv2d-166            [-1, 128, 7, 7]          36,864\n",
      "     BatchNorm2d-167            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-168            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-169            [-1, 832, 7, 7]               0\n",
      "          Conv2d-170            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-171            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-172            [-1, 128, 7, 7]               0\n",
      "       Inception-173            [-1, 832, 7, 7]               0\n",
      "          Conv2d-174            [-1, 384, 7, 7]         319,488\n",
      "     BatchNorm2d-175            [-1, 384, 7, 7]             768\n",
      "     BasicConv2d-176            [-1, 384, 7, 7]               0\n",
      "          Conv2d-177            [-1, 192, 7, 7]         159,744\n",
      "     BatchNorm2d-178            [-1, 192, 7, 7]             384\n",
      "     BasicConv2d-179            [-1, 192, 7, 7]               0\n",
      "          Conv2d-180            [-1, 384, 7, 7]         663,552\n",
      "     BatchNorm2d-181            [-1, 384, 7, 7]             768\n",
      "     BasicConv2d-182            [-1, 384, 7, 7]               0\n",
      "          Conv2d-183             [-1, 48, 7, 7]          39,936\n",
      "     BatchNorm2d-184             [-1, 48, 7, 7]              96\n",
      "     BasicConv2d-185             [-1, 48, 7, 7]               0\n",
      "          Conv2d-186            [-1, 128, 7, 7]          55,296\n",
      "     BatchNorm2d-187            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-188            [-1, 128, 7, 7]               0\n",
      "       MaxPool2d-189            [-1, 832, 7, 7]               0\n",
      "          Conv2d-190            [-1, 128, 7, 7]         106,496\n",
      "     BatchNorm2d-191            [-1, 128, 7, 7]             256\n",
      "     BasicConv2d-192            [-1, 128, 7, 7]               0\n",
      "       Inception-193           [-1, 1024, 7, 7]               0\n",
      "AdaptiveAvgPool2d-194           [-1, 1024, 1, 1]               0\n",
      "         Dropout-195                 [-1, 1024]               0\n",
      "          Linear-196                 [-1, 1000]       1,025,000\n",
      "================================================================\n",
      "Total params: 6,624,904\n",
      "Trainable params: 6,624,904\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 94.11\n",
      "Params size (MB): 25.27\n",
      "Estimated Total Size (MB): 119.95\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model.to('cuda'), (3, 224, 224)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422a3f8",
   "metadata": {},
   "source": [
    "# Demonstrating sorting for first regular convs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "dfe3d4b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 35957.0\n",
      "Switching after sorting 31893.0\n",
      "Percentage of reduction 11.302388964596602 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 244.0\n",
      "Switching after sorting 251.0\n",
      "Percentage of reduction -2.8688524590163933 %\n",
      "Switching before sorting 249.0\n",
      "Switching after sorting 263.0\n",
      "Percentage of reduction -5.622489959839357 %\n",
      "Switching before sorting 220.0\n",
      "Switching after sorting 203.0\n",
      "Percentage of reduction 7.7272727272727275 %\n"
     ]
    }
   ],
   "source": [
    "No_conv_layers=3 # to exlude classifier network\n",
    "sw_wt = np.zeros(No_conv_layers)\n",
    "sw_bn = np.zeros((No_conv_layers, 4))\n",
    "sw_wt_sorted = np.zeros(No_conv_layers)\n",
    "sw_bn_sorted = np.zeros((No_conv_layers, 4))\n",
    "########## sorting conv1.conv ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.conv1.conv.weight)\n",
    "model.conv1.conv.weight.data, _, sw_wt[0], sw_wt_sorted[0]  = compare_sw_sort(model.conv1.conv.weight.data, new_indx1, -3)\n",
    "model.conv1.bn.weight.data, _, sw_bn[0][0], sw_bn_sorted[0][0]  = compare_sw_sort(model.conv1.bn.weight.data, new_indx1, -1)\n",
    "model.conv1.bn.bias.data, _, sw_bn[0][1], sw_bn_sorted[0][1]  = compare_sw_sort(model.conv1.bn.bias.data, new_indx1, -1)\n",
    "model.conv1.bn.running_mean.data, _, sw_bn[0][2], sw_bn_sorted[0][2]  = compare_sw_sort(model.conv1.bn.running_mean.data, new_indx1, -1)\n",
    "model.conv1.bn.running_var.data, _, sw_bn[0][3], sw_bn_sorted[0][3]  = compare_sw_sort(model.conv1.bn.running_var.data, new_indx1, -1)\n",
    "# plot_dist(model.conv1.bn.weight)\n",
    "########## rearranging conv2.conv ##########\n",
    "model.conv2.conv.weight.data = model.conv2.conv.weight[:, new_indx1, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "893365de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 15587.0\n",
      "Switching after sorting 13101.0\n",
      "Percentage of reduction 15.949188426252647 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 243.0\n",
      "Switching after sorting 243.0\n",
      "Percentage of reduction 0.0 %\n",
      "Switching before sorting 251.0\n",
      "Switching after sorting 260.0\n",
      "Percentage of reduction -3.585657370517928 %\n",
      "Switching before sorting 260.0\n",
      "Switching after sorting 262.0\n",
      "Percentage of reduction -0.7692307692307693 %\n"
     ]
    }
   ],
   "source": [
    "########## sorting conv2.conv ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.conv2.conv.weight)\n",
    "model.conv2.conv.weight.data, _, sw_wt[1], sw_wt_sorted[1]  = compare_sw_sort(model.conv2.conv.weight.data, new_indx1, -3)\n",
    "model.conv2.bn.weight.data, _, sw_bn[1][0], sw_bn_sorted[1][0]  = compare_sw_sort(model.conv2.bn.weight.data, new_indx1, -1)\n",
    "model.conv2.bn.bias.data, _, sw_bn[1][1], sw_bn_sorted[1][1]  = compare_sw_sort(model.conv2.bn.bias.data, new_indx1, -1)\n",
    "model.conv2.bn.running_mean.data, _, sw_bn[1][2], sw_bn_sorted[1][2]  = compare_sw_sort(model.conv2.bn.running_mean.data, new_indx1, -1)\n",
    "model.conv2.bn.running_var.data, _, sw_bn[1][3], sw_bn_sorted[1][3]  = compare_sw_sort(model.conv2.bn.running_var.data, new_indx1, -1)\n",
    "# plot_dist(model.conv1.bn.weight)\n",
    "########## rearranging conv3.conv ##########\n",
    "model.conv3.conv.weight.data = model.conv3.conv.weight[:, new_indx1, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "4146ac2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 415246.0\n",
      "Switching after sorting 369064.0\n",
      "Percentage of reduction 11.121600208069433 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 724.0\n",
      "Switching after sorting 682.0\n",
      "Percentage of reduction 5.801104972375691 %\n",
      "Switching before sorting 757.0\n",
      "Switching after sorting 737.0\n",
      "Percentage of reduction 2.642007926023778 %\n",
      "Switching before sorting 677.0\n",
      "Switching after sorting 689.0\n",
      "Percentage of reduction -1.7725258493353029 %\n"
     ]
    }
   ],
   "source": [
    "########## sorting conv3.conv ##########\n",
    "_, new_indx1 = sortFullMatrix_V2(model.conv3.conv.weight)\n",
    "model.conv3.conv.weight.data, _, sw_wt[2], sw_wt_sorted[2]  = compare_sw_sort(model.conv3.conv.weight.data, new_indx1, -3)\n",
    "model.conv3.bn.weight.data, _, sw_bn[2][0], sw_bn_sorted[2][0]  = compare_sw_sort(model.conv3.bn.weight.data, new_indx1, -1)\n",
    "model.conv3.bn.bias.data, _, sw_bn[2][1], sw_bn_sorted[2][1]  = compare_sw_sort(model.conv3.bn.bias.data, new_indx1, -1)\n",
    "model.conv3.bn.running_mean.data, _, sw_bn[2][2], sw_bn_sorted[2][2]  = compare_sw_sort(model.conv3.bn.running_mean.data, new_indx1, -1)\n",
    "model.conv3.bn.running_var.data, _, sw_bn[2][3], sw_bn_sorted[2][3]  = compare_sw_sort(model.conv3.bn.running_var.data, new_indx1, -1)\n",
    "# plot_dist(model.conv1.bn.weight)\n",
    "########## rearranging inception3a.branch1.conv ##########\n",
    "model.inception3a.branch1.conv.weight.data = model.inception3a.branch1.conv.weight[:, new_indx1, :, :]\n",
    "########## rearranging inception3a.branch2.0.conv ##########\n",
    "model.inception3a.branch2[0].conv.weight.data = model.inception3a.branch2[0].conv.weight[:, new_indx1, :, :]\n",
    "########## rearranging inception3a.branch3.0.conv ##########\n",
    "model.inception3a.branch3[0].conv.weight.data = model.inception3a.branch3[0].conv.weight[:, new_indx1, :, :]\n",
    "########## rearranging inception3a.branch4.1.conv ##########\n",
    "model.inception3a.branch4[1].conv.weight.data = model.inception3a.branch4[1].conv.weight[:, new_indx1, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "56d13975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sw_wt before sorting [ 35957.  15587. 415246.]\n",
      "sw_wt_sorted after sorting [ 31893.  13101. 369064.]\n",
      "sw_bn before sorting [[  0. 244. 249. 220.]\n",
      " [  0. 243. 251. 260.]\n",
      " [  0. 724. 757. 677.]]\n",
      "sw_bn_sorted after sorting [[  0. 251. 263. 203.]\n",
      " [  0. 243. 260. 262.]\n",
      " [  0. 682. 737. 689.]]\n"
     ]
    }
   ],
   "source": [
    "print('sw_wt before sorting', sw_wt)\n",
    "print('sw_wt_sorted after sorting', sw_wt_sorted)\n",
    "print('sw_bn before sorting', sw_bn)\n",
    "print('sw_bn_sorted after sorting', sw_bn_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2acf0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57b957e6",
   "metadata": {},
   "source": [
    "# Demonstrating sorting inside the first inception module inception3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ece7a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "No_inc_layers=9 # to exlude classifier network\n",
    "sw_wt = np.zeros((No_inc_layers, 6))\n",
    "# sw_bn = np.zeros((No_inc_layers, 6, 4))\n",
    "sw_wt_sorted = np.zeros((No_inc_layers, 6))\n",
    "# sw_bn_sorted = np.zeros((No_inc_layers, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e470e9af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 46409.0\n",
      "Switching after sorting 41392.0\n",
      "Percentage of reduction 10.810403154560538 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 278.0\n",
      "Switching after sorting 266.0\n",
      "Percentage of reduction 4.316546762589928 %\n",
      "Switching before sorting 284.0\n",
      "Switching after sorting 273.0\n",
      "Percentage of reduction 3.8732394366197185 %\n",
      "Switching before sorting 234.0\n",
      "Switching after sorting 252.0\n",
      "Percentage of reduction -7.6923076923076925 %\n",
      "Switching before sorting 71234.0\n",
      "Switching after sorting 62260.0\n",
      "Percentage of reduction 12.597916725159333 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 391.0\n",
      "Switching after sorting 389.0\n",
      "Percentage of reduction 0.5115089514066496 %\n",
      "Switching before sorting 390.0\n",
      "Switching after sorting 385.0\n",
      "Percentage of reduction 1.2820512820512822 %\n",
      "Switching before sorting 335.0\n",
      "Switching after sorting 329.0\n",
      "Percentage of reduction 1.791044776119403 %\n",
      "Switching before sorting 401397.0\n",
      "Switching after sorting 367114.0\n",
      "Percentage of reduction 8.540920833987299 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 503.0\n",
      "Switching after sorting 495.0\n",
      "Percentage of reduction 1.5904572564612327 %\n",
      "Switching before sorting 501.0\n",
      "Switching after sorting 491.0\n",
      "Percentage of reduction 1.996007984031936 %\n",
      "Switching before sorting 455.0\n",
      "Switching after sorting 470.0\n",
      "Percentage of reduction -3.2967032967032965 %\n",
      "Switching before sorting 11079.0\n",
      "Switching after sorting 9904.0\n",
      "Percentage of reduction 10.605650329452116 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 57.0\n",
      "Switching after sorting 69.0\n",
      "Percentage of reduction -21.05263157894737 %\n",
      "Switching before sorting 53.0\n",
      "Switching after sorting 63.0\n",
      "Percentage of reduction -18.867924528301888 %\n",
      "Switching before sorting 59.0\n",
      "Switching after sorting 60.0\n",
      "Percentage of reduction -1.694915254237288 %\n",
      "Switching before sorting 16162.0\n",
      "Switching after sorting 14254.0\n",
      "Percentage of reduction 11.805469620096522 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 142.0\n",
      "Switching after sorting 108.0\n",
      "Percentage of reduction 23.943661971830984 %\n",
      "Switching before sorting 106.0\n",
      "Switching after sorting 110.0\n",
      "Percentage of reduction -3.7735849056603774 %\n",
      "Switching before sorting 103.0\n",
      "Switching after sorting 98.0\n",
      "Percentage of reduction 4.854368932038835 %\n",
      "Switching before sorting 22585.0\n",
      "Switching after sorting 20167.0\n",
      "Percentage of reduction 10.70622094310383 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 118.0\n",
      "Switching after sorting 126.0\n",
      "Percentage of reduction -6.779661016949152 %\n",
      "Switching before sorting 125.0\n",
      "Switching after sorting 143.0\n",
      "Percentage of reduction -14.4 %\n",
      "Switching before sorting 108.0\n",
      "Switching after sorting 120.0\n",
      "Percentage of reduction -11.11111111111111 %\n"
     ]
    }
   ],
   "source": [
    "# Inception 1\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception3a.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception3a.branch1.conv.weight)\n",
    "model.inception3a.branch1.conv.weight.data, _, sw_wt[0][0], sw_wt_sorted[0][0]  = compare_sw_sort(model.inception3a.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception3a.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception3a.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception3a.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception3a.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception3a.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3a.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception3a.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3a.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception3a.branch2[0].conv.weight)\n",
    "model.inception3a.branch2[0].conv.weight.data, _, sw_wt[0][1], sw_wt_sorted[0][1]  = compare_sw_sort(model.inception3a.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception3a.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception3a.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception3a.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception3a.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception3a.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception3a.branch2[1].conv.weight)\n",
    "model.inception3a.branch2[1].conv.weight.data, _, sw_wt[0][2], sw_wt_sorted[0][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception3a.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception3a.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception3a.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception3a.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3a.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception3a.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception3a.branch3[0].conv.weight)\n",
    "model.inception3a.branch3[0].conv.weight.data, _, sw_wt[0][3], sw_wt_sorted[0][3]  = compare_sw_sort(model.inception3a.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception3a.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception3a.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception3a.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception3a.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception3a.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception3a.branch3[1].conv.weight)\n",
    "model.inception3a.branch3[1].conv.weight.data, _, sw_wt[0][4], sw_wt_sorted[0][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception3a.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception3a.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception3a.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception3a.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3a.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception3a.branch1.conv.weight.shape[0] + model.inception3a.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception3a.branch4[1].conv.weight)\n",
    "model.inception3a.branch4[1].conv.weight.data, _, sw_wt[0][5], sw_wt_sorted[0][5]  = compare_sw_sort(model.inception3a.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception3a.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3a.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception3a.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3a.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception3a.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3a.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception3a.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3a.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception3a.branch1.conv.weight.shape[0] + model.inception3a.branch2[1].conv.weight.shape[0] + model.inception3a.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception3b.branch1.conv.weight.data = model.inception3b.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception3b.branch2[0].conv.weight.data =model.inception3b.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception3b.branch3[0].conv.weight.data = model.inception3b.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception3b.branch4[1].conv.weight.data = model.inception3b.branch4[1].conv.weight[:, new_indxIncp2, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "22e899b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 122703.0\n",
      "Switching after sorting 107634.0\n",
      "Percentage of reduction 12.280873328280482 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 481.0\n",
      "Switching after sorting 457.0\n",
      "Percentage of reduction 4.98960498960499 %\n",
      "Switching before sorting 493.0\n",
      "Switching after sorting 467.0\n",
      "Percentage of reduction 5.273833671399594 %\n",
      "Switching before sorting 391.0\n",
      "Switching after sorting 427.0\n",
      "Percentage of reduction -9.207161125319693 %\n",
      "Switching before sorting 122718.0\n",
      "Switching after sorting 108056.0\n",
      "Percentage of reduction 11.94771753125051 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 466.0\n",
      "Switching after sorting 441.0\n",
      "Percentage of reduction 5.364806866952789 %\n",
      "Switching before sorting 490.0\n",
      "Switching after sorting 490.0\n",
      "Percentage of reduction 0.0 %\n",
      "Switching before sorting 374.0\n",
      "Switching after sorting 354.0\n",
      "Percentage of reduction 5.347593582887701 %\n",
      "Switching before sorting 791884.0\n",
      "Switching after sorting 725872.0\n",
      "Percentage of reduction 8.33606942430962 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 627.0\n",
      "Switching after sorting 629.0\n",
      "Percentage of reduction -0.3189792663476874 %\n",
      "Switching before sorting 657.0\n",
      "Switching after sorting 658.0\n",
      "Percentage of reduction -0.15220700152207 %\n",
      "Switching before sorting 501.0\n",
      "Switching after sorting 534.0\n",
      "Percentage of reduction -6.586826347305389 %\n",
      "Switching before sorting 30178.0\n",
      "Switching after sorting 27190.0\n",
      "Percentage of reduction 9.901252568095964 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 125.0\n",
      "Switching after sorting 110.0\n",
      "Percentage of reduction 12.0 %\n",
      "Switching before sorting 113.0\n",
      "Switching after sorting 108.0\n",
      "Percentage of reduction 4.424778761061947 %\n",
      "Switching before sorting 93.0\n",
      "Switching after sorting 87.0\n",
      "Percentage of reduction 6.451612903225806 %\n",
      "Switching before sorting 101265.0\n",
      "Switching after sorting 89470.0\n",
      "Percentage of reduction 11.64765713721424 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 295.0\n",
      "Switching after sorting 299.0\n",
      "Percentage of reduction -1.3559322033898304 %\n",
      "Switching before sorting 392.0\n",
      "Switching after sorting 365.0\n",
      "Percentage of reduction 6.887755102040816 %\n",
      "Switching before sorting 263.0\n",
      "Switching after sorting 256.0\n",
      "Percentage of reduction 2.661596958174905 %\n",
      "Switching before sorting 60246.0\n",
      "Switching after sorting 53876.0\n",
      "Percentage of reduction 10.573316070776483 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 254.0\n",
      "Switching after sorting 252.0\n",
      "Percentage of reduction 0.7874015748031497 %\n",
      "Switching before sorting 259.0\n",
      "Switching after sorting 251.0\n",
      "Percentage of reduction 3.088803088803089 %\n",
      "Switching before sorting 242.0\n",
      "Switching after sorting 219.0\n",
      "Percentage of reduction 9.50413223140496 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 2\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception3b.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception3b.branch1.conv.weight)\n",
    "model.inception3b.branch1.conv.weight.data, _, sw_wt[1][0], sw_wt_sorted[1][0]  = compare_sw_sort(model.inception3b.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception3b.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception3b.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception3b.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception3b.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception3b.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3b.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception3b.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3b.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception3b.branch2[0].conv.weight)\n",
    "model.inception3b.branch2[0].conv.weight.data, _, sw_wt[1][1], sw_wt_sorted[1][1]  = compare_sw_sort(model.inception3b.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception3b.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception3b.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception3b.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception3b.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception3b.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception3b.branch2[1].conv.weight)\n",
    "model.inception3b.branch2[1].conv.weight.data, _, sw_wt[1][2], sw_wt_sorted[1][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception3b.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception3b.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception3b.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception3b.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3b.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception3b.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception3b.branch3[0].conv.weight)\n",
    "model.inception3b.branch3[0].conv.weight.data, _, sw_wt[1][3], sw_wt_sorted[1][3]  = compare_sw_sort(model.inception3b.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception3b.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception3b.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception3b.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception3b.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception3b.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception3b.branch3[1].conv.weight)\n",
    "model.inception3b.branch3[1].conv.weight.data, _, sw_wt[1][4], sw_wt_sorted[1][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception3b.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception3b.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception3b.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception3b.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3b.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception3b.branch1.conv.weight.shape[0] + model.inception3b.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception3b.branch4[1].conv.weight)\n",
    "model.inception3b.branch4[1].conv.weight.data, _, sw_wt[1][5], sw_wt_sorted[1][5]  = compare_sw_sort(model.inception3b.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception3b.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception3b.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception3b.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception3b.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception3b.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception3b.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception3b.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception3b.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception3b.branch1.conv.weight.shape[0] + model.inception3b.branch2[1].conv.weight.shape[0] + model.inception3b.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception4a.branch1.conv.weight.data = model.inception4a.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4a.branch2[0].conv.weight.data =model.inception4a.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4a.branch3[0].conv.weight.data = model.inception4a.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4a.branch4[1].conv.weight.data = model.inception4a.branch4[1].conv.weight[:, new_indxIncp2, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c81c6295",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 339103.0\n",
      "Switching after sorting 304019.0\n",
      "Percentage of reduction 10.346119025782727 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 730.0\n",
      "Switching after sorting 693.0\n",
      "Percentage of reduction 5.068493150684931 %\n",
      "Switching before sorting 765.0\n",
      "Switching after sorting 735.0\n",
      "Percentage of reduction 3.9215686274509802 %\n",
      "Switching before sorting 688.0\n",
      "Switching after sorting 665.0\n",
      "Percentage of reduction 3.3430232558139537 %\n",
      "Switching before sorting 166546.0\n",
      "Switching after sorting 151218.0\n",
      "Percentage of reduction 9.203463307434582 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 362.0\n",
      "Switching after sorting 364.0\n",
      "Percentage of reduction -0.5524861878453039 %\n",
      "Switching before sorting 390.0\n",
      "Switching after sorting 385.0\n",
      "Percentage of reduction 1.2820512820512822 %\n",
      "Switching before sorting 333.0\n",
      "Switching after sorting 348.0\n",
      "Percentage of reduction -4.504504504504505 %\n",
      "Switching before sorting 642889.0\n",
      "Switching after sorting 586956.0\n",
      "Percentage of reduction 8.700257742782968 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 716.0\n",
      "Switching after sorting 660.0\n",
      "Percentage of reduction 7.82122905027933 %\n",
      "Switching before sorting 738.0\n",
      "Switching after sorting 750.0\n",
      "Percentage of reduction -1.6260162601626016 %\n",
      "Switching before sorting 747.0\n",
      "Switching after sorting 681.0\n",
      "Percentage of reduction 8.835341365461847 %\n",
      "Switching before sorting 25458.0\n",
      "Switching after sorting 23240.0\n",
      "Percentage of reduction 8.712389032916962 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 69.0\n",
      "Switching after sorting 63.0\n",
      "Percentage of reduction 8.695652173913043 %\n",
      "Switching before sorting 64.0\n",
      "Switching after sorting 61.0\n",
      "Percentage of reduction 4.6875 %\n",
      "Switching before sorting 60.0\n",
      "Switching after sorting 64.0\n",
      "Percentage of reduction -6.666666666666667 %\n",
      "Switching before sorting 25496.0\n",
      "Switching after sorting 22491.0\n",
      "Percentage of reduction 11.786162535299654 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 184.0\n",
      "Switching after sorting 147.0\n",
      "Percentage of reduction 20.108695652173914 %\n",
      "Switching before sorting 189.0\n",
      "Switching after sorting 168.0\n",
      "Percentage of reduction 11.11111111111111 %\n",
      "Switching before sorting 171.0\n",
      "Switching after sorting 169.0\n",
      "Percentage of reduction 1.1695906432748537 %\n",
      "Switching before sorting 114067.0\n",
      "Switching after sorting 104420.0\n",
      "Percentage of reduction 8.457310177351907 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 251.0\n",
      "Switching after sorting 246.0\n",
      "Percentage of reduction 1.9920318725099602 %\n",
      "Switching before sorting 273.0\n",
      "Switching after sorting 246.0\n",
      "Percentage of reduction 9.89010989010989 %\n",
      "Switching before sorting 243.0\n",
      "Switching after sorting 249.0\n",
      "Percentage of reduction -2.4691358024691357 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 3\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception4a.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception4a.branch1.conv.weight)\n",
    "model.inception4a.branch1.conv.weight.data, _, sw_wt[2][0], sw_wt_sorted[2][0]  = compare_sw_sort(model.inception4a.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception4a.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception4a.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception4a.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception4a.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception4a.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4a.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception4a.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4a.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception4a.branch2[0].conv.weight)\n",
    "model.inception4a.branch2[0].conv.weight.data, _, sw_wt[2][1], sw_wt_sorted[2][1]  = compare_sw_sort(model.inception4a.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception4a.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception4a.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception4a.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception4a.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception4a.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception4a.branch2[1].conv.weight)\n",
    "model.inception4a.branch2[1].conv.weight.data, _, sw_wt[2][2], sw_wt_sorted[2][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception4a.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception4a.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception4a.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception4a.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4a.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception4a.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception4a.branch3[0].conv.weight)\n",
    "model.inception4a.branch3[0].conv.weight.data, _, sw_wt[2][3], sw_wt_sorted[2][3]  = compare_sw_sort(model.inception4a.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception4a.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception4a.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception4a.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception4a.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception4a.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception4a.branch3[1].conv.weight)\n",
    "model.inception4a.branch3[1].conv.weight.data, _, sw_wt[2][4], sw_wt_sorted[2][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception4a.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception4a.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception4a.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception4a.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4a.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception4a.branch1.conv.weight.shape[0] + model.inception4a.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception4a.branch4[1].conv.weight)\n",
    "model.inception4a.branch4[1].conv.weight.data, _, sw_wt[2][5], sw_wt_sorted[2][5]  = compare_sw_sort(model.inception4a.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception4a.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4a.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception4a.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4a.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception4a.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4a.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception4a.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4a.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception4a.branch1.conv.weight.shape[0] + model.inception4a.branch2[1].conv.weight.shape[0] + model.inception4a.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception4b.branch1.conv.weight.data = model.inception4b.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4b.branch2[0].conv.weight.data =model.inception4b.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4b.branch3[0].conv.weight.data = model.inception4b.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4b.branch4[1].conv.weight.data = model.inception4b.branch4[1].conv.weight[:, new_indxIncp2, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bbc32fa3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 301081.0\n",
      "Switching after sorting 276999.0\n",
      "Percentage of reduction 7.998512028324604 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 587.0\n",
      "Switching after sorting 629.0\n",
      "Percentage of reduction -7.155025553662692 %\n",
      "Switching before sorting 645.0\n",
      "Switching after sorting 620.0\n",
      "Percentage of reduction 3.875968992248062 %\n",
      "Switching before sorting 496.0\n",
      "Switching after sorting 483.0\n",
      "Percentage of reduction 2.620967741935484 %\n",
      "Switching before sorting 213995.0\n",
      "Switching after sorting 192303.0\n",
      "Percentage of reduction 10.13668543657562 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 438.0\n",
      "Switching after sorting 422.0\n",
      "Percentage of reduction 3.65296803652968 %\n",
      "Switching before sorting 424.0\n",
      "Switching after sorting 430.0\n",
      "Percentage of reduction -1.4150943396226414 %\n",
      "Switching before sorting 331.0\n",
      "Switching after sorting 299.0\n",
      "Percentage of reduction 9.667673716012084 %\n",
      "Switching before sorting 788117.0\n",
      "Switching after sorting 723919.0\n",
      "Percentage of reduction 8.14574485767976 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 736.0\n",
      "Switching after sorting 692.0\n",
      "Percentage of reduction 5.978260869565218 %\n",
      "Switching before sorting 770.0\n",
      "Switching after sorting 760.0\n",
      "Percentage of reduction 1.2987012987012987 %\n",
      "Switching before sorting 661.0\n",
      "Switching after sorting 631.0\n",
      "Percentage of reduction 4.53857791225416 %\n",
      "Switching before sorting 43035.0\n",
      "Switching after sorting 40584.0\n",
      "Percentage of reduction 5.695364238410596 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 78.0\n",
      "Switching after sorting 79.0\n",
      "Percentage of reduction -1.2820512820512822 %\n",
      "Switching before sorting 84.0\n",
      "Switching after sorting 73.0\n",
      "Percentage of reduction 13.095238095238095 %\n",
      "Switching before sorting 77.0\n",
      "Switching after sorting 84.0\n",
      "Percentage of reduction -9.090909090909092 %\n",
      "Switching before sorting 49658.0\n",
      "Switching after sorting 44881.0\n",
      "Percentage of reduction 9.619799428088124 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 232.0\n",
      "Switching after sorting 223.0\n",
      "Percentage of reduction 3.8793103448275863 %\n",
      "Switching before sorting 247.0\n",
      "Switching after sorting 253.0\n",
      "Percentage of reduction -2.42914979757085 %\n",
      "Switching before sorting 196.0\n",
      "Switching after sorting 187.0\n",
      "Percentage of reduction 4.591836734693878 %\n",
      "Switching before sorting 121797.0\n",
      "Switching after sorting 112794.0\n",
      "Percentage of reduction 7.391807679992118 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 220.0\n",
      "Switching after sorting 212.0\n",
      "Percentage of reduction 3.6363636363636362 %\n",
      "Switching before sorting 258.0\n",
      "Switching after sorting 250.0\n",
      "Percentage of reduction 3.10077519379845 %\n",
      "Switching before sorting 245.0\n",
      "Switching after sorting 242.0\n",
      "Percentage of reduction 1.2244897959183674 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 4\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception4b.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception4b.branch1.conv.weight)\n",
    "model.inception4b.branch1.conv.weight.data, _, sw_wt[3][0], sw_wt_sorted[3][0]  = compare_sw_sort(model.inception4b.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception4b.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception4b.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception4b.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception4b.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception4b.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4b.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception4b.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4b.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception4b.branch2[0].conv.weight)\n",
    "model.inception4b.branch2[0].conv.weight.data, _, sw_wt[3][1], sw_wt_sorted[3][1]  = compare_sw_sort(model.inception4b.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception4b.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception4b.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception4b.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception4b.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception4b.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception4b.branch2[1].conv.weight)\n",
    "model.inception4b.branch2[1].conv.weight.data, _, sw_wt[3][2], sw_wt_sorted[3][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception4b.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception4b.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception4b.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception4b.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4b.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception4b.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception4b.branch3[0].conv.weight)\n",
    "model.inception4b.branch3[0].conv.weight.data, _, sw_wt[3][3], sw_wt_sorted[3][3]  = compare_sw_sort(model.inception4b.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception4b.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception4b.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception4b.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception4b.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception4b.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception4b.branch3[1].conv.weight)\n",
    "model.inception4b.branch3[1].conv.weight.data, _, sw_wt[3][4], sw_wt_sorted[3][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception4b.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception4b.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception4b.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception4b.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4b.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception4b.branch1.conv.weight.shape[0] + model.inception4b.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception4b.branch4[1].conv.weight)\n",
    "model.inception4b.branch4[1].conv.weight.data, _, sw_wt[3][5], sw_wt_sorted[3][5]  = compare_sw_sort(model.inception4b.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception4b.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4b.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception4b.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4b.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception4b.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4b.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception4b.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4b.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception4b.branch1.conv.weight.shape[0] + model.inception4b.branch2[1].conv.weight.shape[0] + model.inception4b.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception4c.branch1.conv.weight.data = model.inception4c.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4c.branch2[0].conv.weight.data =model.inception4c.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4c.branch3[0].conv.weight.data = model.inception4c.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4c.branch4[1].conv.weight.data = model.inception4c.branch4[1].conv.weight[:, new_indxIncp2, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "6120ebac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 240730.0\n",
      "Switching after sorting 222237.0\n",
      "Percentage of reduction 7.682050429942259 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 517.0\n",
      "Switching after sorting 492.0\n",
      "Percentage of reduction 4.835589941972921 %\n",
      "Switching before sorting 499.0\n",
      "Switching after sorting 506.0\n",
      "Percentage of reduction -1.402805611222445 %\n",
      "Switching before sorting 430.0\n",
      "Switching after sorting 416.0\n",
      "Percentage of reduction 3.255813953488372 %\n",
      "Switching before sorting 249343.0\n",
      "Switching after sorting 223067.0\n",
      "Percentage of reduction 10.538094111324561 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 427.0\n",
      "Switching after sorting 410.0\n",
      "Percentage of reduction 3.981264637002342 %\n",
      "Switching before sorting 466.0\n",
      "Switching after sorting 485.0\n",
      "Percentage of reduction -4.07725321888412 %\n",
      "Switching before sorting 376.0\n",
      "Switching after sorting 370.0\n",
      "Percentage of reduction 1.5957446808510638 %\n",
      "Switching before sorting 1047734.0\n",
      "Switching after sorting 958951.0\n",
      "Percentage of reduction 8.4738111009092 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 854.0\n",
      "Switching after sorting 812.0\n",
      "Percentage of reduction 4.918032786885246 %\n",
      "Switching before sorting 906.0\n",
      "Switching after sorting 887.0\n",
      "Percentage of reduction 2.097130242825607 %\n",
      "Switching before sorting 767.0\n",
      "Switching after sorting 765.0\n",
      "Percentage of reduction 0.2607561929595828 %\n",
      "Switching before sorting 41723.0\n",
      "Switching after sorting 39267.0\n",
      "Percentage of reduction 5.88644153105002 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 96.0\n",
      "Switching after sorting 99.0\n",
      "Percentage of reduction -3.125 %\n",
      "Switching before sorting 105.0\n",
      "Switching after sorting 87.0\n",
      "Percentage of reduction 17.142857142857142 %\n",
      "Switching before sorting 73.0\n",
      "Switching after sorting 65.0\n",
      "Percentage of reduction 10.95890410958904 %\n",
      "Switching before sorting 49590.0\n",
      "Switching after sorting 43146.0\n",
      "Percentage of reduction 12.994555353901996 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 201.0\n",
      "Switching after sorting 199.0\n",
      "Percentage of reduction 0.9950248756218906 %\n",
      "Switching before sorting 228.0\n",
      "Switching after sorting 250.0\n",
      "Percentage of reduction -9.649122807017545 %\n",
      "Switching before sorting 191.0\n",
      "Switching after sorting 170.0\n",
      "Percentage of reduction 10.99476439790576 %\n",
      "Switching before sorting 122820.0\n",
      "Switching after sorting 113180.0\n",
      "Percentage of reduction 7.848884546490799 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 182.0\n",
      "Switching after sorting 204.0\n",
      "Percentage of reduction -12.087912087912088 %\n",
      "Switching before sorting 247.0\n",
      "Switching after sorting 249.0\n",
      "Percentage of reduction -0.8097165991902834 %\n",
      "Switching before sorting 241.0\n",
      "Switching after sorting 206.0\n",
      "Percentage of reduction 14.522821576763485 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 5\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception4c.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception4c.branch1.conv.weight)\n",
    "model.inception4c.branch1.conv.weight.data, _, sw_wt[4][0], sw_wt_sorted[4][0]  = compare_sw_sort(model.inception4c.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception4c.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception4c.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception4c.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception4c.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception4c.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4c.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception4c.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4c.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception4c.branch2[0].conv.weight)\n",
    "model.inception4c.branch2[0].conv.weight.data, _, sw_wt[4][1], sw_wt_sorted[4][1]  = compare_sw_sort(model.inception4c.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception4c.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception4c.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception4c.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception4c.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception4c.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception4c.branch2[1].conv.weight)\n",
    "model.inception4c.branch2[1].conv.weight.data, _, sw_wt[4][2], sw_wt_sorted[4][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception4c.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception4c.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception4c.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception4c.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4c.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception4c.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception4c.branch3[0].conv.weight)\n",
    "model.inception4c.branch3[0].conv.weight.data, _, sw_wt[4][3], sw_wt_sorted[4][3]  = compare_sw_sort(model.inception4c.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception4c.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception4c.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception4c.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception4c.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception4c.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception4c.branch3[1].conv.weight)\n",
    "model.inception4c.branch3[1].conv.weight.data, _, sw_wt[4][4], sw_wt_sorted[4][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception4c.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception4c.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception4c.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception4c.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4c.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception4c.branch1.conv.weight.shape[0] + model.inception4c.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception4c.branch4[1].conv.weight)\n",
    "model.inception4c.branch4[1].conv.weight.data, _, sw_wt[4][5], sw_wt_sorted[4][5]  = compare_sw_sort(model.inception4c.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception4c.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4c.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception4c.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4c.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception4c.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4c.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception4c.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4c.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception4c.branch1.conv.weight.shape[0] + model.inception4c.branch2[1].conv.weight.shape[0] + model.inception4c.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception4d.branch1.conv.weight.data = model.inception4d.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4d.branch2[0].conv.weight.data =model.inception4d.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4d.branch3[0].conv.weight.data = model.inception4d.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4d.branch4[1].conv.weight.data = model.inception4d.branch4[1].conv.weight[:, new_indxIncp2, :, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7bf1e3e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 207582.0\n",
      "Switching after sorting 191527.0\n",
      "Percentage of reduction 7.734292954109701 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 440.0\n",
      "Switching after sorting 421.0\n",
      "Percentage of reduction 4.318181818181818 %\n",
      "Switching before sorting 447.0\n",
      "Switching after sorting 448.0\n",
      "Percentage of reduction -0.22371364653243847 %\n",
      "Switching before sorting 335.0\n",
      "Switching after sorting 331.0\n",
      "Percentage of reduction 1.1940298507462686 %\n",
      "Switching before sorting 276674.0\n",
      "Switching after sorting 251977.0\n",
      "Percentage of reduction 8.926389902918237 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 460.0\n",
      "Switching after sorting 478.0\n",
      "Percentage of reduction -3.9130434782608696 %\n",
      "Switching before sorting 494.0\n",
      "Switching after sorting 484.0\n",
      "Percentage of reduction 2.0242914979757085 %\n",
      "Switching before sorting 422.0\n",
      "Switching after sorting 383.0\n",
      "Percentage of reduction 9.24170616113744 %\n",
      "Switching before sorting 1314867.0\n",
      "Switching after sorting 1209593.0\n",
      "Percentage of reduction 8.006437152959197 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 942.0\n",
      "Switching after sorting 937.0\n",
      "Percentage of reduction 0.5307855626326964 %\n",
      "Switching before sorting 1039.0\n",
      "Switching after sorting 1001.0\n",
      "Percentage of reduction 3.6573628488931664 %\n",
      "Switching before sorting 829.0\n",
      "Switching after sorting 835.0\n",
      "Percentage of reduction -0.7237635705669482 %\n",
      "Switching before sorting 58815.0\n",
      "Switching after sorting 53092.0\n",
      "Percentage of reduction 9.730510924083992 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 132.0\n",
      "Switching after sorting 122.0\n",
      "Percentage of reduction 7.575757575757576 %\n",
      "Switching before sorting 126.0\n",
      "Switching after sorting 119.0\n",
      "Percentage of reduction 5.555555555555555 %\n",
      "Switching before sorting 105.0\n",
      "Switching after sorting 92.0\n",
      "Percentage of reduction 12.380952380952381 %\n",
      "Switching before sorting 67032.0\n",
      "Switching after sorting 59110.0\n",
      "Percentage of reduction 11.818236066356366 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 226.0\n",
      "Switching after sorting 224.0\n",
      "Percentage of reduction 0.8849557522123894 %\n",
      "Switching before sorting 228.0\n",
      "Switching after sorting 230.0\n",
      "Percentage of reduction -0.8771929824561403 %\n",
      "Switching before sorting 188.0\n",
      "Switching after sorting 189.0\n",
      "Percentage of reduction -0.5319148936170213 %\n",
      "Switching before sorting 121556.0\n",
      "Switching after sorting 111817.0\n",
      "Percentage of reduction 8.011945111718056 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 184.0\n",
      "Switching after sorting 175.0\n",
      "Percentage of reduction 4.891304347826087 %\n",
      "Switching before sorting 251.0\n",
      "Switching after sorting 234.0\n",
      "Percentage of reduction 6.772908366533865 %\n",
      "Switching before sorting 210.0\n",
      "Switching after sorting 207.0\n",
      "Percentage of reduction 1.4285714285714286 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 6\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception4d.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception4d.branch1.conv.weight)\n",
    "model.inception4d.branch1.conv.weight.data, _, sw_wt[5][0], sw_wt_sorted[5][0]  = compare_sw_sort(model.inception4d.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception4d.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception4d.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception4d.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception4d.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception4d.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4d.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception4d.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4d.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception4d.branch2[0].conv.weight)\n",
    "model.inception4d.branch2[0].conv.weight.data, _, sw_wt[5][1], sw_wt_sorted[5][1]  = compare_sw_sort(model.inception4d.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception4d.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception4d.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception4d.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception4d.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception4d.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception4d.branch2[1].conv.weight)\n",
    "model.inception4d.branch2[1].conv.weight.data, _, sw_wt[5][2], sw_wt_sorted[5][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception4d.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception4d.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception4d.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception4d.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4d.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception4d.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception4d.branch3[0].conv.weight)\n",
    "model.inception4d.branch3[0].conv.weight.data, _, sw_wt[5][3], sw_wt_sorted[5][3]  = compare_sw_sort(model.inception4d.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception4d.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception4d.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception4d.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception4d.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception4d.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception4d.branch3[1].conv.weight)\n",
    "model.inception4d.branch3[1].conv.weight.data, _, sw_wt[5][4], sw_wt_sorted[5][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception4d.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception4d.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception4d.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception4d.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4d.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception4d.branch1.conv.weight.shape[0] + model.inception4d.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception4d.branch4[1].conv.weight)\n",
    "model.inception4d.branch4[1].conv.weight.data, _, sw_wt[5][5], sw_wt_sorted[5][5]  = compare_sw_sort(model.inception4d.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception4d.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4d.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception4d.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4d.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception4d.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4d.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception4d.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4d.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception4d.branch1.conv.weight.shape[0] + model.inception4d.branch2[1].conv.weight.shape[0] + model.inception4d.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception4e.branch1.conv.weight.data = model.inception4e.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4e.branch2[0].conv.weight.data =model.inception4e.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4e.branch3[0].conv.weight.data = model.inception4e.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception4e.branch4[1].conv.weight.data = model.inception4e.branch4[1].conv.weight[:, new_indxIncp2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dc3646dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 505420.0\n",
      "Switching after sorting 458379.0\n",
      "Percentage of reduction 9.307308772901745 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 860.0\n",
      "Switching after sorting 849.0\n",
      "Percentage of reduction 1.2790697674418605 %\n",
      "Switching before sorting 838.0\n",
      "Switching after sorting 794.0\n",
      "Percentage of reduction 5.250596658711217 %\n",
      "Switching before sorting 608.0\n",
      "Switching after sorting 594.0\n",
      "Percentage of reduction 2.3026315789473686 %\n",
      "Switching before sorting 322037.0\n",
      "Switching after sorting 295558.0\n",
      "Percentage of reduction 8.22234712160404 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 500.0\n",
      "Switching after sorting 514.0\n",
      "Percentage of reduction -2.8 %\n",
      "Switching before sorting 558.0\n",
      "Switching after sorting 544.0\n",
      "Percentage of reduction 2.5089605734767026 %\n",
      "Switching before sorting 415.0\n",
      "Switching after sorting 445.0\n",
      "Percentage of reduction -7.228915662650603 %\n",
      "Switching before sorting 1601572.0\n",
      "Switching after sorting 1481897.0\n",
      "Percentage of reduction 7.472345920133469 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 1131.0\n",
      "Switching after sorting 1061.0\n",
      "Percentage of reduction 6.18921308576481 %\n",
      "Switching before sorting 1002.0\n",
      "Switching after sorting 982.0\n",
      "Percentage of reduction 1.996007984031936 %\n",
      "Switching before sorting 861.0\n",
      "Switching after sorting 861.0\n",
      "Percentage of reduction 0.0 %\n",
      "Switching before sorting 60805.0\n",
      "Switching after sorting 56542.0\n",
      "Percentage of reduction 7.0109366006085025 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 119.0\n",
      "Switching after sorting 112.0\n",
      "Percentage of reduction 5.882352941176471 %\n",
      "Switching before sorting 126.0\n",
      "Switching after sorting 125.0\n",
      "Percentage of reduction 0.7936507936507936 %\n",
      "Switching before sorting 91.0\n",
      "Switching after sorting 92.0\n",
      "Percentage of reduction -1.098901098901099 %\n",
      "Switching before sorting 135035.0\n",
      "Switching after sorting 117060.0\n",
      "Percentage of reduction 13.311363720516903 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 454.0\n",
      "Switching after sorting 428.0\n",
      "Percentage of reduction 5.726872246696035 %\n",
      "Switching before sorting 469.0\n",
      "Switching after sorting 480.0\n",
      "Percentage of reduction -2.345415778251599 %\n",
      "Switching before sorting 427.0\n",
      "Switching after sorting 398.0\n",
      "Percentage of reduction 6.791569086651054 %\n",
      "Switching before sorting 254589.0\n",
      "Switching after sorting 234146.0\n",
      "Percentage of reduction 8.029804901232968 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 378.0\n",
      "Switching after sorting 405.0\n",
      "Percentage of reduction -7.142857142857143 %\n",
      "Switching before sorting 447.0\n",
      "Switching after sorting 443.0\n",
      "Percentage of reduction 0.8948545861297539 %\n",
      "Switching before sorting 469.0\n",
      "Switching after sorting 448.0\n",
      "Percentage of reduction 4.477611940298507 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 7\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception4e.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception4e.branch1.conv.weight)\n",
    "model.inception4e.branch1.conv.weight.data, _, sw_wt[6][0], sw_wt_sorted[6][0]  = compare_sw_sort(model.inception4e.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception4e.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception4e.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception4e.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception4e.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception4e.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4e.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception4e.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4e.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception4e.branch2[0].conv.weight)\n",
    "model.inception4e.branch2[0].conv.weight.data, _, sw_wt[6][1], sw_wt_sorted[6][1]  = compare_sw_sort(model.inception4e.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception4e.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception4e.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception4e.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception4e.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception4e.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception4e.branch2[1].conv.weight)\n",
    "model.inception4e.branch2[1].conv.weight.data, _, sw_wt[6][2], sw_wt_sorted[6][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception4e.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception4e.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception4e.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception4e.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4e.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception4e.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception4e.branch3[0].conv.weight)\n",
    "model.inception4e.branch3[0].conv.weight.data, _, sw_wt[6][3], sw_wt_sorted[6][3]  = compare_sw_sort(model.inception4e.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception4e.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception4e.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception4e.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception4e.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception4e.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception4e.branch3[1].conv.weight)\n",
    "model.inception4e.branch3[1].conv.weight.data, _, sw_wt[6][4], sw_wt_sorted[6][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception4e.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception4e.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception4e.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception4e.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4e.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception4e.branch1.conv.weight.shape[0] + model.inception4e.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception4e.branch4[1].conv.weight)\n",
    "model.inception4e.branch4[1].conv.weight.data, _, sw_wt[6][5], sw_wt_sorted[6][5]  = compare_sw_sort(model.inception4e.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception4e.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception4e.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception4e.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception4e.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception4e.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception4e.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception4e.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception4e.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception4e.branch1.conv.weight.shape[0] + model.inception4e.branch2[1].conv.weight.shape[0] + model.inception4e.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception5a.branch1.conv.weight.data = model.inception5a.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception5a.branch2[0].conv.weight.data =model.inception5a.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception5a.branch3[0].conv.weight.data = model.inception5a.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception5a.branch4[1].conv.weight.data = model.inception5a.branch4[1].conv.weight[:, new_indxIncp2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ca1813b0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 785122.0\n",
      "Switching after sorting 728124.0\n",
      "Percentage of reduction 7.259763450775803 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 885.0\n",
      "Switching after sorting 880.0\n",
      "Percentage of reduction 0.5649717514124294 %\n",
      "Switching before sorting 660.0\n",
      "Switching after sorting 711.0\n",
      "Percentage of reduction -7.7272727272727275 %\n",
      "Switching before sorting 466.0\n",
      "Switching after sorting 471.0\n",
      "Percentage of reduction -1.0729613733905579 %\n",
      "Switching before sorting 498903.0\n",
      "Switching after sorting 465094.0\n",
      "Percentage of reduction 6.776668009613091 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 503.0\n",
      "Switching after sorting 461.0\n",
      "Percentage of reduction 8.34990059642147 %\n",
      "Switching before sorting 523.0\n",
      "Switching after sorting 541.0\n",
      "Percentage of reduction -3.4416826003824093 %\n",
      "Switching before sorting 475.0\n",
      "Switching after sorting 453.0\n",
      "Percentage of reduction 4.631578947368421 %\n",
      "Switching before sorting 1601072.0\n",
      "Switching after sorting 1469553.0\n",
      "Percentage of reduction 8.214433829334347 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 1078.0\n",
      "Switching after sorting 1052.0\n",
      "Percentage of reduction 2.411873840445269 %\n",
      "Switching before sorting 1078.0\n",
      "Switching after sorting 1027.0\n",
      "Percentage of reduction 4.7309833024118735 %\n",
      "Switching before sorting 987.0\n",
      "Switching after sorting 967.0\n",
      "Percentage of reduction 2.026342451874367 %\n",
      "Switching before sorting 96112.0\n",
      "Switching after sorting 91389.0\n",
      "Percentage of reduction 4.914058598301981 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 93.0\n",
      "Switching after sorting 92.0\n",
      "Percentage of reduction 1.075268817204301 %\n",
      "Switching before sorting 75.0\n",
      "Switching after sorting 89.0\n",
      "Percentage of reduction -18.666666666666668 %\n",
      "Switching before sorting 76.0\n",
      "Switching after sorting 83.0\n",
      "Percentage of reduction -9.210526315789474 %\n",
      "Switching before sorting 136782.0\n",
      "Switching after sorting 115059.0\n",
      "Percentage of reduction 15.881475632758697 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 416.0\n",
      "Switching after sorting 411.0\n",
      "Percentage of reduction 1.2019230769230769 %\n",
      "Switching before sorting 417.0\n",
      "Switching after sorting 408.0\n",
      "Percentage of reduction 2.158273381294964 %\n",
      "Switching before sorting 380.0\n",
      "Switching after sorting 365.0\n",
      "Percentage of reduction 3.9473684210526314 %\n",
      "Switching before sorting 394429.0\n",
      "Switching after sorting 370489.0\n",
      "Percentage of reduction 6.069533426801782 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 381.0\n",
      "Switching after sorting 385.0\n",
      "Percentage of reduction -1.0498687664041995 %\n",
      "Switching before sorting 529.0\n",
      "Switching after sorting 455.0\n",
      "Percentage of reduction 13.988657844990549 %\n",
      "Switching before sorting 499.0\n",
      "Switching after sorting 482.0\n",
      "Percentage of reduction 3.406813627254509 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 8\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception5a.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception5a.branch1.conv.weight)\n",
    "model.inception5a.branch1.conv.weight.data, _, sw_wt[7][0], sw_wt_sorted[7][0]  = compare_sw_sort(model.inception5a.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception5a.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception5a.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception5a.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception5a.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception5a.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5a.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception5a.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5a.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception5a.branch2[0].conv.weight)\n",
    "model.inception5a.branch2[0].conv.weight.data, _, sw_wt[7][1], sw_wt_sorted[7][1]  = compare_sw_sort(model.inception5a.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception5a.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception5a.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception5a.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception5a.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception5a.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception5a.branch2[1].conv.weight)\n",
    "model.inception5a.branch2[1].conv.weight.data, _, sw_wt[7][2], sw_wt_sorted[7][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception5a.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception5a.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception5a.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception5a.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5a.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception5a.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception5a.branch3[0].conv.weight)\n",
    "model.inception5a.branch3[0].conv.weight.data, _, sw_wt[7][3], sw_wt_sorted[7][3]  = compare_sw_sort(model.inception5a.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception5a.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception5a.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception5a.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception5a.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception5a.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception5a.branch3[1].conv.weight)\n",
    "model.inception5a.branch3[1].conv.weight.data, _, sw_wt[7][4], sw_wt_sorted[7][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception5a.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception5a.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception5a.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception5a.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5a.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception5a.branch1.conv.weight.shape[0] + model.inception5a.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception5a.branch4[1].conv.weight)\n",
    "model.inception5a.branch4[1].conv.weight.data, _, sw_wt[7][5], sw_wt_sorted[7][5]  = compare_sw_sort(model.inception5a.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception5a.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5a.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception5a.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5a.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception5a.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5a.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception5a.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5a.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception5a.branch1.conv.weight.shape[0] + model.inception5a.branch2[1].conv.weight.shape[0] + model.inception5a.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "\n",
    "# Rearranging all branchs of inception 2 along channel dimension to correct Branch 1 sortng \n",
    "model.inception5b.branch1.conv.weight.data = model.inception5b.branch1.conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception5b.branch2[0].conv.weight.data =model.inception5b.branch2[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception5b.branch3[0].conv.weight.data = model.inception5b.branch3[0].conv.weight[:, new_indxIncp2, :, :]\n",
    "model.inception5b.branch4[1].conv.weight.data = model.inception5b.branch4[1].conv.weight[:, new_indxIncp2, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "69cc7f0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting 974141.0\n",
      "Switching after sorting 881309.0\n",
      "Percentage of reduction 9.529626614627656 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 763.0\n",
      "Switching after sorting 736.0\n",
      "Percentage of reduction 3.5386631716906947 %\n",
      "Switching before sorting 760.0\n",
      "Switching after sorting 779.0\n",
      "Percentage of reduction -2.5 %\n",
      "Switching before sorting 117.0\n",
      "Switching after sorting 107.0\n",
      "Percentage of reduction 8.547008547008547 %\n",
      "Switching before sorting 612600.0\n",
      "Switching after sorting 572582.0\n",
      "Percentage of reduction 6.532484492327783 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 602.0\n",
      "Switching after sorting 614.0\n",
      "Percentage of reduction -1.9933554817275747 %\n",
      "Switching before sorting 574.0\n",
      "Switching after sorting 587.0\n",
      "Percentage of reduction -2.264808362369338 %\n",
      "Switching before sorting 584.0\n",
      "Switching after sorting 581.0\n",
      "Percentage of reduction 0.5136986301369864 %\n",
      "Switching before sorting 1490417.0\n",
      "Switching after sorting 1291618.0\n",
      "Percentage of reduction 13.338481780602342 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 753.0\n",
      "Switching after sorting 686.0\n",
      "Percentage of reduction 8.897742363877821 %\n",
      "Switching before sorting 356.0\n",
      "Switching after sorting 334.0\n",
      "Percentage of reduction 6.179775280898877 %\n",
      "Switching before sorting 28.0\n",
      "Switching after sorting 12.0\n",
      "Percentage of reduction 57.142857142857146 %\n",
      "Switching before sorting 148579.0\n",
      "Switching after sorting 140943.0\n",
      "Percentage of reduction 5.139353475255588 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 114.0\n",
      "Switching after sorting 137.0\n",
      "Percentage of reduction -20.17543859649123 %\n",
      "Switching before sorting 128.0\n",
      "Switching after sorting 137.0\n",
      "Percentage of reduction -7.03125 %\n",
      "Switching before sorting 141.0\n",
      "Switching after sorting 126.0\n",
      "Percentage of reduction 10.638297872340425 %\n",
      "Switching before sorting 132633.0\n",
      "Switching after sorting 103247.0\n",
      "Percentage of reduction 22.155873726749753 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 422.0\n",
      "Switching after sorting 486.0\n",
      "Percentage of reduction -15.165876777251185 %\n",
      "Switching before sorting 75.0\n",
      "Switching after sorting 65.0\n",
      "Percentage of reduction 13.333333333333334 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 375670.0\n",
      "Switching after sorting 349149.0\n",
      "Percentage of reduction 7.059653419224319 %\n",
      "Switching before sorting 0.0\n",
      "Switching after sorting 0.0\n",
      "Percentage of reduction nan %\n",
      "Switching before sorting 325.0\n",
      "Switching after sorting 280.0\n",
      "Percentage of reduction 13.846153846153847 %\n",
      "Switching before sorting 399.0\n",
      "Switching after sorting 378.0\n",
      "Percentage of reduction 5.2631578947368425 %\n",
      "Switching before sorting 62.0\n",
      "Switching after sorting 62.0\n",
      "Percentage of reduction 0.0 %\n"
     ]
    }
   ],
   "source": [
    "## Inception 9\n",
    "# Branch 1\n",
    "# conv1_weight_reshaped, new_indx1 = sortFullMatrix(np.asarray(conv1_weight_reshaped.to('cpu').detach().numpy()))\n",
    "# new_indxb1 = torch.randperm(model.inception5b.branch1.conv.weight.shape[0])\n",
    "_, new_indxb1 = sortFullMatrix_V2(model.inception5b.branch1.conv.weight)\n",
    "model.inception5b.branch1.conv.weight.data, _, sw_wt[8][0], sw_wt_sorted[8][0]  = compare_sw_sort(model.inception5b.branch1.conv.weight.data, new_indxb1, -3)\n",
    "model.inception5b.branch1.bn.weight.data, _, _, _  = compare_sw_sort(model.inception5b.branch1.bn.weight.data, new_indxb1, -1)\n",
    "model.inception5b.branch1.bn.bias.data, _, _, _  = compare_sw_sort(model.inception5b.branch1.bn.bias.data, new_indxb1, -1)\n",
    "model.inception5b.branch1.bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5b.branch1.bn.running_mean.data, new_indxb1, -1)\n",
    "model.inception5b.branch1.bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5b.branch1.bn.running_var.data, new_indxb1, -1)\n",
    "\n",
    "# Branch 2\n",
    "# conv 1x1\n",
    "_, new_indxb2a = sortFullMatrix_V2(model.inception5b.branch2[0].conv.weight)\n",
    "model.inception5b.branch2[0].conv.weight.data, _, sw_wt[8][1], sw_wt_sorted[8][1]  = compare_sw_sort(model.inception5b.branch2[0].conv.weight.data, new_indxb2a, -3)\n",
    "model.inception5b.branch2[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[0].bn.weight.data, new_indxb2a, -1)\n",
    "model.inception5b.branch2[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[0].bn.bias.data, new_indxb2a, -1)\n",
    "model.inception5b.branch2[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[0].bn.running_mean.data, new_indxb2a, -1)\n",
    "model.inception5b.branch2[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[0].bn.running_var.data, new_indxb2a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b2conv2_weight = model.inception5b.branch2[1].conv.weight[:, new_indxb2a, :, :]  # Re-arranging along channel\n",
    "_, new_indxb2b = sortFullMatrix_V2(model.inception5b.branch2[1].conv.weight)\n",
    "model.inception5b.branch2[1].conv.weight.data, _, sw_wt[8][2], sw_wt_sorted[8][2]  = compare_sw_sort(new_b2conv2_weight.data, new_indxb2b, -3)\n",
    "model.inception5b.branch2[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[1].bn.weight.data, new_indxb2b, -1)\n",
    "model.inception5b.branch2[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[1].bn.bias.data, new_indxb2b, -1)\n",
    "model.inception5b.branch2[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[1].bn.running_mean.data, new_indxb2b, -1)\n",
    "model.inception5b.branch2[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5b.branch2[1].bn.running_var.data, new_indxb2b, -1)\n",
    "\n",
    "new_indxb2b = new_indxb2b + model.inception5b.branch1.conv.weight.shape[0] # incrementing all indeces  b2b for concatenation at the second layer\n",
    "\n",
    "# Branch 3\n",
    "# conv 1x1\n",
    "_, new_indxb3a = sortFullMatrix_V2(model.inception5b.branch3[0].conv.weight)\n",
    "model.inception5b.branch3[0].conv.weight.data, _, sw_wt[8][3], sw_wt_sorted[8][3]  = compare_sw_sort(model.inception5b.branch3[0].conv.weight.data, new_indxb3a, -3)\n",
    "model.inception5b.branch3[0].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[0].bn.weight.data, new_indxb3a, -1)\n",
    "model.inception5b.branch3[0].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[0].bn.bias.data, new_indxb3a, -1)\n",
    "model.inception5b.branch3[0].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[0].bn.running_mean.data, new_indxb3a, -1)\n",
    "model.inception5b.branch3[0].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[0].bn.running_var.data, new_indxb3a, -1)\n",
    "\n",
    "# conv 3x3\n",
    "new_b3conv2_weight = model.inception5b.branch3[1].conv.weight[:, new_indxb3a, :, :]  \n",
    "_, new_indxb3b = sortFullMatrix_V2(model.inception5b.branch3[1].conv.weight)\n",
    "model.inception5b.branch3[1].conv.weight.data, _, sw_wt[8][4], sw_wt_sorted[8][4]  = compare_sw_sort(new_b3conv2_weight.data, new_indxb3b, -3)\n",
    "model.inception5b.branch3[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[1].bn.weight.data, new_indxb3b, -1)\n",
    "model.inception5b.branch3[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[1].bn.bias.data, new_indxb3b, -1)\n",
    "model.inception5b.branch3[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[1].bn.running_mean.data, new_indxb3b, -1)\n",
    "model.inception5b.branch3[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5b.branch3[1].bn.running_var.data, new_indxb3b, -1)\n",
    "new_indxb3b = new_indxb3b + model.inception5b.branch1.conv.weight.shape[0] + model.inception5b.branch2[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "# Branch 4\n",
    "_, new_indxb4 = sortFullMatrix_V2(model.inception5b.branch4[1].conv.weight)\n",
    "model.inception5b.branch4[1].conv.weight.data, _, sw_wt[8][5], sw_wt_sorted[8][5]  = compare_sw_sort(model.inception5b.branch4[1].conv.weight.data, new_indxb4, -3)\n",
    "model.inception5b.branch4[1].bn.weight.data, _, _, _  = compare_sw_sort(model.inception5b.branch4[1].bn.weight.data, new_indxb4, -1)\n",
    "model.inception5b.branch4[1].bn.bias.data, _, _, _  = compare_sw_sort(model.inception5b.branch4[1].bn.bias.data, new_indxb4, -1)\n",
    "model.inception5b.branch4[1].bn.running_mean.data, _, _, _  = compare_sw_sort(model.inception5b.branch4[1].bn.running_mean.data, new_indxb4, -1)\n",
    "model.inception5b.branch4[1].bn.running_var.data, _, _, _  = compare_sw_sort(model.inception5b.branch4[1].bn.running_var.data, new_indxb4, -1)\n",
    "\n",
    "new_indxb4 = new_indxb4 + model.inception5b.branch1.conv.weight.shape[0] + model.inception5b.branch2[1].conv.weight.shape[0] + model.inception5b.branch3[1].conv.weight.shape[0] # incrementing all indeces  b3b for concatenation at the second layer\n",
    "\n",
    "new_indxIncp2 = np.concatenate((new_indxb1, new_indxb2b, new_indxb3b, new_indxb4), 0) #np.concatenate\n",
    "\n",
    "\n",
    "# Rearranging all branchs of fc\n",
    "model.fc.weight.data = model.fc.weight[:, new_indxIncp2] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e45357df",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw_wtConv = np.array([ 35957,  15587, 415246])\n",
    "sw_wt_sortedConv = np.array([ 31893,  13101, 369064])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e5396845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switching before sorting [[  46409.   71234.  401397.   11079.   16162.   22585.]\n",
      " [ 122703.  122718.  791884.   30178.  101265.   60246.]\n",
      " [ 339103.  166546.  642889.   25458.   25496.  114067.]\n",
      " [ 301081.  213995.  788117.   43035.   49658.  121797.]\n",
      " [ 240730.  249343. 1047734.   41723.   49590.  122820.]\n",
      " [ 207582.  276674. 1314867.   58815.   67032.  121556.]\n",
      " [ 505420.  322037. 1601572.   60805.  135035.  254589.]\n",
      " [ 785122.  498903. 1601072.   96112.  136782.  394429.]\n",
      " [ 974141.  612600. 1490417.  148579.  132633.  375670.]]\n",
      "Switching after sorting [[  41392.   62260.  367114.    9904.   14254.   20167.]\n",
      " [ 107634.  108056.  725872.   27190.   89470.   53876.]\n",
      " [ 304019.  151218.  586956.   23240.   22491.  104420.]\n",
      " [ 276999.  192303.  723919.   40584.   44881.  112794.]\n",
      " [ 222237.  223067.  958951.   39267.   43146.  113180.]\n",
      " [ 191527.  251977. 1209593.   53092.   59110.  111817.]\n",
      " [ 458379.  295558. 1481897.   56542.  117060.  234146.]\n",
      " [ 728124.  465094. 1469553.   91389.  115059.  370489.]\n",
      " [ 881309.  572582. 1291618.  140943.  103247.  349149.]]\n"
     ]
    }
   ],
   "source": [
    "print('Switching before sorting', sw_wt) \n",
    "print('Switching after sorting', sw_wt_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "43654a84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of reduction in switching across all inception modules [0.11302389 0.15949188 0.111216  ]\n",
      "Percentage of reduction in switching across all inception modules [0.0882014  0.08363489 0.08930584 0.06520753 0.14703925 0.07414286]\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of reduction in switching across the first conv blocks', (sw_wtConv-sw_wt_sortedConv)/sw_wtConv)\n",
    "print('Percentage of reduction in switching across all inception modules', (np.sum(sw_wt, 0)-np.sum(sw_wt_sorted, 0))/np.sum(sw_wt, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "72b6f4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000])\n",
      "torch.Size([1000])\n"
     ]
    }
   ],
   "source": [
    "# sample execution (requires torchvision)\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "filename = 'dog.jpg'\n",
    "input_image = Image.open(filename)\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "input_tensor = preprocess(input_image)\n",
    "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "\n",
    "# move the input and model to GPU for speed if available\n",
    "if torch.cuda.is_available():\n",
    "    input_batch = input_batch.to('cuda')\n",
    "    model.to('cuda')\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_batch)\n",
    "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
    "print(output[0].shape)\n",
    "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
    "print(probabilities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e7e8f3cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samoyed 0.9378383755683899\n",
      "Pomeranian 0.008283410221338272\n",
      "Great Pyrenees 0.005603067111223936\n",
      "Arctic fox 0.005527761299163103\n",
      "white wolf 0.004741047043353319\n"
     ]
    }
   ],
   "source": [
    "# Read the categories\n",
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "# Show top categories per image\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7ca8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download an example image from the pytorch website\n",
    "# import urllib\n",
    "# url, filename = (\"https://github.com/pytorch/hub/raw/master/images/dog.jpg\", \"dog.jpg\")\n",
    "# try: urllib.URLopener().retrieve(url, filename)\n",
    "# except: urllib.request.urlretrieve(url, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "136c78ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download ImageNet labels\n",
    "# !wget https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
